# PostgreSQL Query Optimization

Techniques and patterns for optimizing PostgreSQL queries in high-traffic applications.

## Understanding Query Plans

Always start with `EXPLAIN ANALYZE`:

```sql
EXPLAIN ANALYZE
SELECT u.name, COUNT(p.id) as post_count
FROM users u
LEFT JOIN posts p ON u.id = p.user_id
WHERE u.created_at > '2024-01-01'
GROUP BY u.id, u.name
ORDER BY post_count DESC
LIMIT 10;
```

<Callout type="info" title="Reading Plans">
Focus on: Seq Scan vs Index Scan, nested loops, hash joins, and actual vs estimated rows.
</Callout>

## Indexing Strategies

### Basic Indexes
```sql
-- Single column index
CREATE INDEX idx_users_email ON users(email);

-- Composite index (order matters!)
CREATE INDEX idx_posts_user_created 
ON posts(user_id, created_at DESC);
```

### Partial Indexes
For frequently filtered queries:

```sql
-- Only index active users
CREATE INDEX idx_active_users 
ON users(email) 
WHERE status = 'active';
```

### Expression Indexes
For computed values:

```sql
CREATE INDEX idx_users_lower_email 
ON users(LOWER(email));

-- Now this query uses the index
SELECT * FROM users WHERE LOWER(email) = 'user@example.com';
```

## N+1 Query Problem

<Callout type="error" title="Common Issue">
Loading related data in a loop causes exponential query growth.
</Callout>

**Bad:**
```typescript
// N+1 queries: 1 + N
const users = await db.users.findMany();
for (const user of users) {
  user.posts = await db.posts.findMany({ where: { userId: user.id } });
}
```

**Good:**
```typescript
// Single query with join
const users = await db.users.findMany({
  include: { posts: true }
});
```

## Connection Pooling

```typescript
import { Pool } from 'pg';

const pool = new Pool({
  host: 'localhost',
  database: 'mydb',
  max: 20, // Max connections
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000,
});

// Use pool instead of individual connections
const result = await pool.query('SELECT * FROM users WHERE id = $1', [userId]);
```

## Batch Operations

Instead of individual inserts:

```sql
-- Bad: Multiple round trips
INSERT INTO users (name, email) VALUES ('Alice', 'alice@example.com');
INSERT INTO users (name, email) VALUES ('Bob', 'bob@example.com');
INSERT INTO users (name, email) VALUES ('Charlie', 'charlie@example.com');

-- Good: Single query
INSERT INTO users (name, email) VALUES 
  ('Alice', 'alice@example.com'),
  ('Bob', 'bob@example.com'),
  ('Charlie', 'charlie@example.com');
```

## Materialized Views

For expensive aggregate queries:

```sql
CREATE MATERIALIZED VIEW user_statistics AS
SELECT 
  u.id,
  u.name,
  COUNT(DISTINCT p.id) as post_count,
  COUNT(DISTINCT c.id) as comment_count,
  MAX(p.created_at) as last_post_date
FROM users u
LEFT JOIN posts p ON u.id = p.user_id
LEFT JOIN comments c ON u.id = c.user_id
GROUP BY u.id, u.name;

-- Refresh periodically
REFRESH MATERIALIZED VIEW user_statistics;
```

<Callout type="success">
Materialized views reduced our dashboard load time from 8s to 200ms.
</Callout>

## Monitoring Queries

Track slow queries:

```sql
-- Enable slow query logging
ALTER SYSTEM SET log_min_duration_statement = 1000; -- Log queries > 1s
SELECT pg_reload_conf();

-- View currently running queries
SELECT 
  pid,
  now() - query_start as duration,
  query
FROM pg_stat_activity
WHERE state = 'active'
ORDER BY duration DESC;
```

## Production Metrics

From our optimization work:

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Avg Query Time | 450ms | 85ms | 81% faster |
| P95 Latency | 2.3s | 320ms | 86% faster |
| DB CPU Usage | 78% | 32% | 59% reduction |

---

*Placeholder content - replace with your actual PostgreSQL experiments.*
